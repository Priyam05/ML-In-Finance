{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Linear Regression with TensorFlow__\n",
    "There are three ways to fit linear regression model to the data\n",
    "\n",
    "1. Normal Equation\n",
    "2. Maximum Likelihood Estimation\n",
    "3. Stochastic Gradient Descent with Mini-Batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math as m\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import  Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility function to make this notebook's output stable across the runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We use artificial data for the following regression__<br>\n",
    "y(x)=a+$b_1$.$X_1$+$b_2$.$X_2$+$b_3$.$X_3$+$\\sigma$.$\\epsilon$ <br>\n",
    "where $\\epsilon$ ~ N(0,1) as a Guassian noise and $\\sigma$ is its volatility, with the following choice of parameters:<br>\n",
    "a=1.0<br>\n",
    "$b_1$,$b_2$, $b_3$ = (0.5, 0.2, 0.1)<br>\n",
    "$\\sigma$=0.1<br>\n",
    "$X_1$, $X_2$, $X_3$ will be uniformly distributed in [-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generate data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points=5000\n",
    "n_features=3\n",
    "\n",
    "bias=np.ones(n_points).reshape(-1,1)\n",
    "low=-np.ones((n_points, n_features),'float')\n",
    "high=np.ones((n_points, n_features),'float')\n",
    "\n",
    "#simulated features/inputs \n",
    "X=np.random.uniform(low=low, high=high)\n",
    "\n",
    "#simulated noise\n",
    "noise=np.random.normal(size=(n_points,1))\n",
    "\n",
    "#outputs\n",
    "weights=np.array([1.0,0.5,0.2,0.1])  #here a=0.1\n",
    "noise_std=0.1\n",
    "Y=weights[0]*bias+np.dot(X,weights[1:]).reshape(-1,1)+noise_std*noise\n",
    "\n",
    "#split to the train and test set\n",
    "train_test_split=4 #1/4 of the data is used for test\n",
    "\n",
    "n_test=int(n_points/train_test_split)\n",
    "n_train=n_points-n_test\n",
    "\n",
    "X_train= X[:n_train,:]\n",
    "Y_train=Y[:n_train,:].reshape(-1,1)\n",
    "\n",
    "X_test=X[n_train:,:]\n",
    "Y_test=Y[n_train:,:].reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3750, 3), (3750, 1), (1250, 3), (1250, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Linear Regression with NumPy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99753201]\n",
      " [0.50184089]\n",
      " [0.20008112]\n",
      " [0.09929622]]\n"
     ]
    }
   ],
   "source": [
    "#add the column of ones\n",
    "X=np.hstack((np.ones(n_train).reshape(-1,1),X_train))\n",
    "\n",
    "theta_numpy=np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y_train) \n",
    "\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Linear Regression with sklearn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99753201]\n",
      " [0.50184089]\n",
      " [0.20008112]\n",
      " [0.09929622]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train,Y_train)\n",
    "\n",
    "#lin_reg.intercept_ is the bias term, lin_reg.coef_ is the weights corresponding to given features\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1,1),lin_reg.coef_.T]) #np.r_ joins the array vertically like np.vstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Linear Regression with Tensorflow__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9975319 ],\n",
       "       [0.5018408 ],\n",
       "       [0.20008114],\n",
       "       [0.09929623]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add the column of ones like we added in the Numpy method\n",
    "X_np=np.hstack((np.ones(n_train).reshape(-1,1),X_train))\n",
    "\n",
    "X=tf.constant(X_np,dtype=tf.float32, name='X')\n",
    "y=tf.constant(Y_train, dtype=tf.float32, name='y')\n",
    "XT=tf.transpose(X)\n",
    "theta=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_val=theta.eval()\n",
    "    \n",
    "theta_val\n",
    "\n",
    "#This is same as Numpy method. Just that we used the Tensorflow functions instead Numpy function for Matrix calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create class for Linear Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegressNormalEq:\n",
    "    def __init__(self, n_features, learning_rate=0.5, L=0):\n",
    "        import math as m\n",
    "        #input placeholders\n",
    "        self.X=tf.placeholder(tf.float32,[None,n_features],name='X')\n",
    "        self.Y=tf.placeholder(tf.float32,[None,1],name='Y')\n",
    "        \n",
    "        #regression parameters for the analytical solution using Normal Equation\n",
    "        self.theta_in=tf.placeholder(tf.float32,[n_features+1,None])\n",
    "        \n",
    "        #Augmented data matrix is obtained by adding a column of ones to the data matrix\n",
    "        data_plus_bias=tf.concat([tf.ones([tf.shape(self.X)[0],1]),self.X],axis=1)\n",
    "        XT=tf.transpose(data_plus_bias)\n",
    "        \n",
    "        # The normal equation for Linear Regression\n",
    "        self.theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, data_plus_bias)), XT), self.Y)\n",
    "        \n",
    "        # mean square error in terms of theta = theta_in\n",
    "        self.lr_mse = tf.reduce_mean(tf.square(tf.matmul(data_plus_bias, self.theta_in) - self.Y))\n",
    "        \n",
    "    #enter() and exit() function needs to be created if class is used with 'with' block\n",
    "    def __enter__(self):\n",
    "        print(\"__enter__\")\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback): #__exit__ function has 4 arguments by default\n",
    "        print(\"__exit__\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_normal_eq(X_train, Y_train, X_test, Y_test, learning_rate=0.05):\n",
    "    \"\"\"\n",
    "    Implements normal equation using tensorflow, trains the model using training data set\n",
    "    Tests the model quality by computing mean square error (MSE) of the test data set\n",
    "    \n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    X_test  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_test - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    \n",
    "    Return a tuple of:\n",
    "        - np.array of size (k+1 by 1) of regression coefficients\n",
    "        - mean square error (MSE) of the test data set\n",
    "        - mean square error (MSE) of the training data set\n",
    "    \"\"\"\n",
    "    # create an instance of the Linear Regression model class  \n",
    "    n_features = X_train.shape[1]\n",
    "    #model = LinRegressNormalEq(n_features=n_features, learning_rate=learning_rate)\n",
    "    \n",
    "    with LinRegressNormalEq(n_features=n_features, learning_rate=learning_rate) as model:\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            theta_value=sess.run(model.theta, feed_dict={model.X: X_train, model.Y: Y_train})\n",
    "            lr_mse_train =sess.run(model.lr_mse,feed_dict={model.X:X_train,model.Y:Y_train,model.theta_in:theta_value})\n",
    "            lr_mse_test =sess.run(model.lr_mse,feed_dict={model.X:X_test,model.Y:Y_test,model.theta_in:theta_value})\n",
    "        \n",
    "    return theta_value, lr_mse_train,lr_mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__enter__\n",
      "__exit__\n"
     ]
    }
   ],
   "source": [
    "theta_value, lr_mse_train, lr_mse_test = run_normal_eq(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0026565 ],\n",
       "       [0.50068945],\n",
       "       [0.1956349 ],\n",
       "       [0.09993321]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normal Equation function with 'with' block of class Linear Regression. Notice: Enter and Exit function doesnt get called here.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_normal_eq2(X_train, Y_train, X_test, Y_test, learning_rate=0.05):\n",
    "    \"\"\"\n",
    "    Implements normal equation using tensorflow, trains the model using training data set\n",
    "    Tests the model quality by computing mean square error (MSE) of the test data set\n",
    "    \n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    X_test  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_test - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    \n",
    "    Return a tuple of:\n",
    "        - np.array of size (k+1 by 1) of regression coefficients\n",
    "        - mean square error (MSE) of the test data set\n",
    "        - mean square error (MSE) of the training data set\n",
    "    \"\"\"\n",
    "    # create an instance of the Linear Regression model class  \n",
    "    n_features = X_train.shape[1]\n",
    "    #model = LinRegressNormalEq(n_features=n_features, learning_rate=learning_rate)\n",
    "    \n",
    "    model=LinRegressNormalEq(n_features=n_features, learning_rate=learning_rate)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        theta_value=sess.run(model.theta, feed_dict={model.X: X_train, model.Y: Y_train})\n",
    "        lr_mse_train =sess.run(model.lr_mse,feed_dict={model.X:X_train,model.Y:Y_train,model.theta_in:theta_value})\n",
    "        lr_mse_test =sess.run(model.lr_mse,feed_dict={model.X:X_test,model.Y:Y_test,model.theta_in:theta_value})\n",
    "        \n",
    "    return theta_value, lr_mse_train,lr_mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_value, lr_mse_train, lr_mse_test = run_normal_eq2(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0026565 ],\n",
       "       [0.50068945],\n",
       "       [0.1956349 ],\n",
       "       [0.09993321]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
